{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Bibliotecas**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install tensorflow\n",
    "%pip install matplotlib\n",
    "%pip install pandas\n",
    "%pip install numpy\n",
    "%pip install itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Carregar Dataset**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LIBRAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "input_shape = (64, 64, 3)\n",
    "# input_shape = (75, 75, 3)  # InceptionV3 input size\n",
    "\n",
    "train_path = f\"../datasets/libras/{input_shape[0]}x{input_shape[1]}/train/\"\n",
    "test_path  = f\"../datasets/libras/{input_shape[0]}x{input_shape[1]}/test/\"\n",
    "\n",
    "classes = os.listdir(train_path)\n",
    "classes = sorted(classes)\n",
    "n_classes = len(classes)\n",
    "print(f\"Classes: {classes}\")\n",
    "\n",
    "file_count = []\n",
    "\n",
    "for fld in os.listdir(train_path):\n",
    "    crt = os.path.join(train_path, fld)\n",
    "    image_count = len(os.listdir(crt))\n",
    "    file_count.append(image_count)\n",
    "    print(f'{crt} contains {image_count} images')\n",
    "\n",
    "print(f'\\nTotal number of images: {sum(file_count)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pessoal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "input_shape = (64, 64, 3)\n",
    "# input_shape = (75, 75, 3)  # InceptionV3 input size\n",
    "\n",
    "train_path = f\"../datasets/personal/clean/{input_shape[0]}x{input_shape[1]}/train/\"\n",
    "test_path  = f\"../datasets/personal/clean/{input_shape[0]}x{input_shape[1]}/test/\"\n",
    "\n",
    "classes = os.listdir(train_path)\n",
    "classes = sorted(classes)\n",
    "n_classes = len(classes)\n",
    "print(f\"Classes: {classes}\")\n",
    "\n",
    "file_count = []\n",
    "\n",
    "for fld in os.listdir(train_path):\n",
    "    crt = os.path.join(train_path, fld)\n",
    "    image_count = len(os.listdir(crt))\n",
    "    file_count.append(image_count)\n",
    "    print(f'{crt} contains {image_count} images')\n",
    "\n",
    "print(f'\\nTotal number of images: {sum(file_count)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Carregar modelo**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## InceptionV3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications.inception_v3 import preprocess_input\n",
    "from keras.models import load_model\n",
    "\n",
    "# Define channel place\n",
    "keras.backend.set_image_data_format('channels_last')\n",
    "\n",
    "## Define constants\n",
    "BATCH_SIZE = 32\n",
    "SEED = 123\n",
    "\n",
    "## Data augmentation and preprocessing\n",
    "# Validation Gen\n",
    "val_data_generator = ImageDataGenerator(\n",
    "    validation_split=0.2,\n",
    "    preprocessing_function=preprocess_input,\n",
    ")\n",
    "\n",
    "validation_generator = val_data_generator.flow_from_directory(\n",
    "    train_path,\n",
    "    target_size=input_shape[:2],\n",
    "    shuffle=False,\n",
    "    seed=SEED,\n",
    "    class_mode='categorical',\n",
    "    batch_size=BATCH_SIZE,\n",
    "    subset=\"validation\"\n",
    ")\n",
    "\n",
    "# Test Gen\n",
    "test_generator = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input,\n",
    ")\n",
    "test_generator = test_generator.flow_from_directory(\n",
    "    test_path,\n",
    "    target_size=input_shape[:2],\n",
    "    shuffle=False,\n",
    "    seed=SEED,\n",
    "    class_mode='categorical',\n",
    "    batch_size=BATCH_SIZE,\n",
    ")\n",
    "\n",
    "## Image quantity\n",
    "validation_samples = validation_generator.samples\n",
    "test_samples = test_generator.samples\n",
    "\n",
    "## Model\n",
    "model = load_model(\"./InceptionV3/libras/inception_v3_model.h5\")\n",
    "# model = load_model(\"./InceptionV3/personal/inception_v3_model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications.resnet50 import preprocess_input\n",
    "from keras.models import load_model\n",
    "\n",
    "# Define channel place\n",
    "keras.backend.set_image_data_format('channels_last')\n",
    "\n",
    "## Define constants\n",
    "BATCH_SIZE = 32\n",
    "SEED = 123\n",
    "\n",
    "## Data augmentation and preprocessing\n",
    "# Validation Gen\n",
    "val_data_generator = ImageDataGenerator(\n",
    "    validation_split=0.2,\n",
    "    preprocessing_function=preprocess_input,\n",
    "    rescale=1./255,\n",
    ")\n",
    "\n",
    "validation_generator = val_data_generator.flow_from_directory(\n",
    "    train_path,\n",
    "    target_size=input_shape[:2],\n",
    "    shuffle=False,\n",
    "    seed=SEED,\n",
    "    class_mode='categorical',\n",
    "    batch_size=BATCH_SIZE,\n",
    "    subset=\"validation\"\n",
    ")\n",
    "\n",
    "# Test Gen\n",
    "test_generator = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input,\n",
    "    rescale=1./255,\n",
    ")\n",
    "test_generator = test_generator.flow_from_directory(\n",
    "    test_path,\n",
    "    target_size=input_shape[:2],\n",
    "    shuffle=False,\n",
    "    seed=SEED,\n",
    "    class_mode='categorical',\n",
    "    batch_size=BATCH_SIZE,\n",
    ")\n",
    "\n",
    "## Image quantity\n",
    "validation_samples = validation_generator.samples\n",
    "test_samples = test_generator.samples\n",
    "\n",
    "## Model\n",
    "model = load_model(\"./ResNet50/libras/resnet50_model.h5\")\n",
    "# model = load_model(\"./InceptionV3/personal/inception_v3_model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Testes**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funções"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def classification_report_csv(report):\n",
    "  report_data = []\n",
    "  lines = report.split('\\n')\n",
    "  for line in lines[2:-3]:\n",
    "      row = {}\n",
    "      row_data = [d for d in line.split(' ') if d!='']\n",
    "      if (len(row_data) == 5):\n",
    "        row['class'] = row_data[0]\n",
    "        row['precision'] = float(row_data[1])\n",
    "        row['recall'] = float(row_data[2])\n",
    "        row['f1_score'] = float(row_data[3])\n",
    "        row['support'] = float(row_data[4])\n",
    "        report_data.append(row)\n",
    "  dataframe = pd.DataFrame.from_dict(report_data)\n",
    "  # dataframe.to_csv(f'{filepath}classification_report.csv', index = False)\n",
    "\n",
    "#Plot the confusion matrix. Set Normalize = True/False\n",
    "def plot_confusion_matrix(cm, classes, normalize=True, title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        cm = np.around(cm, decimals=2)\n",
    "        cm[np.isnan(cm)] = 0.0\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    # plt.savefig(f'{filepath}confusion_matrix.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Validation\n",
    "score = model.evaluate(validation_generator)\n",
    "print('Validation loss:', score[0])\n",
    "print('Validation accuracy:', score[1])\n",
    "\n",
    "# Test\n",
    "score = model.evaluate(test_generator)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "## Some reports\n",
    "# On test dataset\n",
    "Y_pred = model.predict(test_generator)\n",
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "target_names = classes\n",
    "\n",
    "# Confution Matrix\n",
    "cm = confusion_matrix(test_generator.classes, y_pred)\n",
    "plot_confusion_matrix(cm, target_names, normalize=False, title='Confusion Matrix')\n",
    "\n",
    "# Classification Report\n",
    "print('Classification Report')\n",
    "report = classification_report(test_generator.classes, y_pred, target_names=target_names)\n",
    "classification_report_csv(report)\n",
    "print(report)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
