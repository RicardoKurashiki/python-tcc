{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Download das bibliotecas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pip in c:\\users\\ricardo\\documents\\github\\pessoal\\tcc\\python-tcc\\training\\.venv\\lib\\site-packages (23.2.1)\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Requirement already satisfied: tensorflow in c:\\users\\ricardo\\documents\\github\\pessoal\\tcc\\python-tcc\\training\\.venv\\lib\\site-packages (2.13.0)\n",
            "Requirement already satisfied: tensorflow-intel==2.13.0 in c:\\users\\ricardo\\documents\\github\\pessoal\\tcc\\python-tcc\\training\\.venv\\lib\\site-packages (from tensorflow) (2.13.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\ricardo\\documents\\github\\pessoal\\tcc\\python-tcc\\training\\.venv\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\ricardo\\documents\\github\\pessoal\\tcc\\python-tcc\\training\\.venv\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.1.21 in c:\\users\\ricardo\\documents\\github\\pessoal\\tcc\\python-tcc\\training\\.venv\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (23.5.26)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in c:\\users\\ricardo\\documents\\github\\pessoal\\tcc\\python-tcc\\training\\.venv\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\ricardo\\documents\\github\\pessoal\\tcc\\python-tcc\\training\\.venv\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\ricardo\\documents\\github\\pessoal\\tcc\\python-tcc\\training\\.venv\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\ricardo\\documents\\github\\pessoal\\tcc\\python-tcc\\training\\.venv\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (16.0.6)\n",
            "Requirement already satisfied: numpy<=1.24.3,>=1.22 in c:\\users\\ricardo\\documents\\github\\pessoal\\tcc\\python-tcc\\training\\.venv\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.24.3)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\ricardo\\documents\\github\\pessoal\\tcc\\python-tcc\\training\\.venv\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in c:\\users\\ricardo\\documents\\github\\pessoal\\tcc\\python-tcc\\training\\.venv\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (23.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\ricardo\\documents\\github\\pessoal\\tcc\\python-tcc\\training\\.venv\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (4.24.3)\n",
            "Requirement already satisfied: setuptools in c:\\users\\ricardo\\documents\\github\\pessoal\\tcc\\python-tcc\\training\\.venv\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (65.5.0)\n",
            "Requirement already satisfied: six>=1.12.0 in c:\\users\\ricardo\\documents\\github\\pessoal\\tcc\\python-tcc\\training\\.venv\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\ricardo\\documents\\github\\pessoal\\tcc\\python-tcc\\training\\.venv\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (2.3.0)\n",
            "Requirement already satisfied: typing-extensions<4.6.0,>=3.6.6 in c:\\users\\ricardo\\documents\\github\\pessoal\\tcc\\python-tcc\\training\\.venv\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (4.5.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\ricardo\\documents\\github\\pessoal\\tcc\\python-tcc\\training\\.venv\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.15.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\ricardo\\documents\\github\\pessoal\\tcc\\python-tcc\\training\\.venv\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.58.0)\n",
            "Requirement already satisfied: tensorboard<2.14,>=2.13 in c:\\users\\ricardo\\documents\\github\\pessoal\\tcc\\python-tcc\\training\\.venv\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (2.13.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.14,>=2.13.0 in c:\\users\\ricardo\\documents\\github\\pessoal\\tcc\\python-tcc\\training\\.venv\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (2.13.0)\n",
            "Requirement already satisfied: keras<2.14,>=2.13.1 in c:\\users\\ricardo\\documents\\github\\pessoal\\tcc\\python-tcc\\training\\.venv\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (2.13.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\ricardo\\documents\\github\\pessoal\\tcc\\python-tcc\\training\\.venv\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (0.31.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\ricardo\\documents\\github\\pessoal\\tcc\\python-tcc\\training\\.venv\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.13.0->tensorflow) (0.41.2)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\ricardo\\documents\\github\\pessoal\\tcc\\python-tcc\\training\\.venv\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2.22.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in c:\\users\\ricardo\\documents\\github\\pessoal\\tcc\\python-tcc\\training\\.venv\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\ricardo\\documents\\github\\pessoal\\tcc\\python-tcc\\training\\.venv\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (3.4.4)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\ricardo\\documents\\github\\pessoal\\tcc\\python-tcc\\training\\.venv\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\ricardo\\documents\\github\\pessoal\\tcc\\python-tcc\\training\\.venv\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (0.7.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\ricardo\\documents\\github\\pessoal\\tcc\\python-tcc\\training\\.venv\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2.3.7)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\ricardo\\documents\\github\\pessoal\\tcc\\python-tcc\\training\\.venv\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (5.3.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\ricardo\\documents\\github\\pessoal\\tcc\\python-tcc\\training\\.venv\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\ricardo\\documents\\github\\pessoal\\tcc\\python-tcc\\training\\.venv\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (4.9)\n",
            "Requirement already satisfied: urllib3<2.0 in c:\\users\\ricardo\\documents\\github\\pessoal\\tcc\\python-tcc\\training\\.venv\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (1.26.16)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\ricardo\\documents\\github\\pessoal\\tcc\\python-tcc\\training\\.venv\\lib\\site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\ricardo\\documents\\github\\pessoal\\tcc\\python-tcc\\training\\.venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ricardo\\documents\\github\\pessoal\\tcc\\python-tcc\\training\\.venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ricardo\\documents\\github\\pessoal\\tcc\\python-tcc\\training\\.venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2023.7.22)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\ricardo\\documents\\github\\pessoal\\tcc\\python-tcc\\training\\.venv\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2.1.3)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in c:\\users\\ricardo\\documents\\github\\pessoal\\tcc\\python-tcc\\training\\.venv\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\ricardo\\documents\\github\\pessoal\\tcc\\python-tcc\\training\\.venv\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (3.2.2)\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Collecting tensorflow-gpu\n",
            "  Using cached tensorflow-gpu-2.12.0.tar.gz (2.6 kB)\n",
            "  Preparing metadata (setup.py): started\n",
            "  Preparing metadata (setup.py): finished with status 'done'\n",
            "Collecting python_version>\"3.7\" (from tensorflow-gpu)\n",
            "  Using cached python_version-0.0.2-py2.py3-none-any.whl (3.4 kB)\n",
            "Building wheels for collected packages: tensorflow-gpu\n",
            "  Building wheel for tensorflow-gpu (setup.py): started\n",
            "  Building wheel for tensorflow-gpu (setup.py): finished with status 'error'\n",
            "  Running setup.py clean for tensorflow-gpu\n",
            "Failed to build tensorflow-gpu\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  error: subprocess-exited-with-error\n",
            "  \n",
            "  × python setup.py bdist_wheel did not run successfully.\n",
            "  │ exit code: 1\n",
            "  ╰─> [18 lines of output]\n",
            "      Traceback (most recent call last):\n",
            "        File \"<string>\", line 2, in <module>\n",
            "        File \"<pip-setuptools-caller>\", line 34, in <module>\n",
            "        File \"C:\\Users\\Ricardo\\AppData\\Local\\Temp\\pip-install-ib1w9y4z\\tensorflow-gpu_a37dad6402ee4c63b7b398dbca447815\\setup.py\", line 37, in <module>\n",
            "          raise Exception(TF_REMOVAL_WARNING)\n",
            "      Exception:\n",
            "      \n",
            "      =========================================================\n",
            "      The \"tensorflow-gpu\" package has been removed!\n",
            "      \n",
            "      Please install \"tensorflow\" instead.\n",
            "      \n",
            "      Other than the name, the two packages have been identical\n",
            "      since TensorFlow 2.1, or roughly since Sep 2019. For more\n",
            "      information, see: pypi.org/project/tensorflow-gpu\n",
            "      =========================================================\n",
            "      \n",
            "      \n",
            "      [end of output]\n",
            "  \n",
            "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  ERROR: Failed building wheel for tensorflow-gpu\n",
            "ERROR: Could not build wheels for tensorflow-gpu, which is required to install pyproject.toml-based projects\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: matplotlib in c:\\users\\ricardo\\documents\\github\\pessoal\\tcc\\python-tcc\\training\\.venv\\lib\\site-packages (3.7.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\ricardo\\documents\\github\\pessoal\\tcc\\python-tcc\\training\\.venv\\lib\\site-packages (from matplotlib) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in c:\\users\\ricardo\\documents\\github\\pessoal\\tcc\\python-tcc\\training\\.venv\\lib\\site-packages (from matplotlib) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\ricardo\\documents\\github\\pessoal\\tcc\\python-tcc\\training\\.venv\\lib\\site-packages (from matplotlib) (4.42.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\ricardo\\documents\\github\\pessoal\\tcc\\python-tcc\\training\\.venv\\lib\\site-packages (from matplotlib) (1.4.5)\n",
            "Requirement already satisfied: numpy>=1.20 in c:\\users\\ricardo\\documents\\github\\pessoal\\tcc\\python-tcc\\training\\.venv\\lib\\site-packages (from matplotlib) (1.24.3)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\users\\ricardo\\documents\\github\\pessoal\\tcc\\python-tcc\\training\\.venv\\lib\\site-packages (from matplotlib) (23.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\ricardo\\documents\\github\\pessoal\\tcc\\python-tcc\\training\\.venv\\lib\\site-packages (from matplotlib) (10.0.0)\n",
            "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in c:\\users\\ricardo\\documents\\github\\pessoal\\tcc\\python-tcc\\training\\.venv\\lib\\site-packages (from matplotlib) (3.0.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\ricardo\\documents\\github\\pessoal\\tcc\\python-tcc\\training\\.venv\\lib\\site-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\ricardo\\documents\\github\\pessoal\\tcc\\python-tcc\\training\\.venv\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Requirement already satisfied: scipy in c:\\users\\ricardo\\documents\\github\\pessoal\\tcc\\python-tcc\\training\\.venv\\lib\\site-packages (1.11.2)\n",
            "Requirement already satisfied: numpy<1.28.0,>=1.21.6 in c:\\users\\ricardo\\documents\\github\\pessoal\\tcc\\python-tcc\\training\\.venv\\lib\\site-packages (from scipy) (1.24.3)\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Requirement already satisfied: pandas in c:\\users\\ricardo\\documents\\github\\pessoal\\tcc\\python-tcc\\training\\.venv\\lib\\site-packages (2.1.0)\n",
            "Requirement already satisfied: numpy>=1.22.4 in c:\\users\\ricardo\\documents\\github\\pessoal\\tcc\\python-tcc\\training\\.venv\\lib\\site-packages (from pandas) (1.24.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\ricardo\\documents\\github\\pessoal\\tcc\\python-tcc\\training\\.venv\\lib\\site-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in c:\\users\\ricardo\\documents\\github\\pessoal\\tcc\\python-tcc\\training\\.venv\\lib\\site-packages (from pandas) (2023.3.post1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\ricardo\\documents\\github\\pessoal\\tcc\\python-tcc\\training\\.venv\\lib\\site-packages (from pandas) (2023.3)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\ricardo\\documents\\github\\pessoal\\tcc\\python-tcc\\training\\.venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Requirement already satisfied: opencv_python in c:\\users\\ricardo\\documents\\github\\pessoal\\tcc\\python-tcc\\training\\.venv\\lib\\site-packages (4.8.0.76)\n",
            "Requirement already satisfied: numpy>=1.21.2 in c:\\users\\ricardo\\documents\\github\\pessoal\\tcc\\python-tcc\\training\\.venv\\lib\\site-packages (from opencv_python) (1.24.3)\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Requirement already satisfied: numpy in c:\\users\\ricardo\\documents\\github\\pessoal\\tcc\\python-tcc\\training\\.venv\\lib\\site-packages (1.24.3)\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Requirement already satisfied: sklearn in c:\\users\\ricardo\\documents\\github\\pessoal\\tcc\\python-tcc\\training\\.venv\\lib\\site-packages (0.0.post9)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install --upgrade pip\n",
        "%pip install tensorflow\n",
        "%pip install tensorflow-gpu\n",
        "%pip install matplotlib\n",
        "%pip install scipy\n",
        "%pip install pandas\n",
        "%pip install opencv_python\n",
        "%pip install numpy\n",
        "%pip install sklearn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mc9MWwirNpex"
      },
      "source": [
        "# Treinamento do modelo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0eCaVf6YNthK"
      },
      "source": [
        "### Carregando o Dataset Pessoal"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ClkVwLK3NrRc",
        "outputId": "d65f1b8f-5bc9-4db1-a059-d49c240e2e1e"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "train_path = \"../datasets/personal/clean/64x64/train/\"\n",
        "test_path  = \"../datasets/personal/clean/64x64/test/\"\n",
        "\n",
        "classes = os.listdir(train_path)\n",
        "classes = sorted(classes)\n",
        "n_classes = len(classes)\n",
        "print(f\"Classes: {classes}\")\n",
        "\n",
        "input_shape = (64, 64, 3)\n",
        "file_count = []\n",
        "\n",
        "for fld in os.listdir(train_path):\n",
        "    crt = os.path.join(train_path, fld)\n",
        "    image_count = len(os.listdir(crt))\n",
        "    file_count.append(image_count)\n",
        "    print(f'{crt} contains {image_count} images')\n",
        "\n",
        "print(f'\\nTotal number of images: {sum(file_count)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Carregando o dataset - Lucas Lacerda\n",
        "https://github.com/lucaaslb/cnn-libras/tree/master"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Classes: ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'I', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'Y']\n",
            "../datasets/libras/64x64/train/A contains 1615 images\n",
            "../datasets/libras/64x64/train/B contains 1615 images\n",
            "../datasets/libras/64x64/train/C contains 1615 images\n",
            "../datasets/libras/64x64/train/D contains 1615 images\n",
            "../datasets/libras/64x64/train/E contains 1615 images\n",
            "../datasets/libras/64x64/train/F contains 1615 images\n",
            "../datasets/libras/64x64/train/G contains 1615 images\n",
            "../datasets/libras/64x64/train/I contains 1615 images\n",
            "../datasets/libras/64x64/train/L contains 1615 images\n",
            "../datasets/libras/64x64/train/M contains 1615 images\n",
            "../datasets/libras/64x64/train/N contains 1615 images\n",
            "../datasets/libras/64x64/train/O contains 1615 images\n",
            "../datasets/libras/64x64/train/P contains 1615 images\n",
            "../datasets/libras/64x64/train/Q contains 1615 images\n",
            "../datasets/libras/64x64/train/R contains 1615 images\n",
            "../datasets/libras/64x64/train/S contains 1615 images\n",
            "../datasets/libras/64x64/train/T contains 1614 images\n",
            "../datasets/libras/64x64/train/U contains 1615 images\n",
            "../datasets/libras/64x64/train/V contains 1615 images\n",
            "../datasets/libras/64x64/train/W contains 1615 images\n",
            "../datasets/libras/64x64/train/Y contains 1615 images\n",
            "\n",
            "Total number of images: 33914\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "train_path = \"../datasets/libras/64x64/train/\"\n",
        "test_path  = \"../datasets/libras/64x64/test/\"\n",
        "\n",
        "classes = os.listdir(train_path)\n",
        "classes = sorted(classes)\n",
        "n_classes = len(classes)\n",
        "print(f\"Classes: {classes}\")\n",
        "\n",
        "input_shape = (64, 64, 3)  # InceptionV3 input size\n",
        "file_count = []\n",
        "\n",
        "for fld in os.listdir(train_path):\n",
        "    crt = os.path.join(train_path, fld)\n",
        "    image_count = len(os.listdir(crt))\n",
        "    file_count.append(image_count)\n",
        "    print(f'{crt} contains {image_count} images')\n",
        "\n",
        "print(f'\\nTotal number of images: {sum(file_count)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h-wthKtncC3r"
      },
      "source": [
        "### Criando Generators"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ww7ElxPccKJk",
        "outputId": "2a95552b-57e9-461a-8533-47d1827e8334"
      },
      "outputs": [],
      "source": [
        "from tensorflow import keras\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.applications.resnet50 import preprocess_input\n",
        "\n",
        "# Define channel place\n",
        "keras.backend.set_image_data_format('channels_last')\n",
        "\n",
        "## Define constants\n",
        "BATCH_SIZE = 32\n",
        "SEED = 123\n",
        "\n",
        "## Data augmentation and preprocessing\n",
        "# Training Gen\n",
        "train_data_generator = ImageDataGenerator(\n",
        "    preprocessing_function=preprocess_input,\n",
        "    validation_split=0.2,\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest',\n",
        "    rescale=1./255,\n",
        ")\n",
        "\n",
        "train_generator = train_data_generator.flow_from_directory(\n",
        "    train_path,\n",
        "    target_size=input_shape[:2],\n",
        "    shuffle=True,\n",
        "    seed=SEED,\n",
        "    class_mode='categorical',\n",
        "    batch_size=BATCH_SIZE,\n",
        "    subset=\"training\"\n",
        ")\n",
        "\n",
        "# Validation Gen\n",
        "val_data_generator = ImageDataGenerator(\n",
        "    validation_split=0.2,\n",
        "    preprocessing_function=preprocess_input,\n",
        "    rescale=1./255,\n",
        ")\n",
        "\n",
        "validation_generator = val_data_generator.flow_from_directory(\n",
        "    train_path,\n",
        "    target_size=input_shape[:2],\n",
        "    shuffle=False,\n",
        "    seed=SEED,\n",
        "    class_mode='categorical',\n",
        "    batch_size=BATCH_SIZE,\n",
        "    subset=\"validation\"\n",
        ")\n",
        "\n",
        "# Test Gen\n",
        "test_generator = ImageDataGenerator(\n",
        "    preprocessing_function=preprocess_input,\n",
        "    rescale=1./255,\n",
        ")\n",
        "test_generator = test_generator.flow_from_directory(\n",
        "    test_path,\n",
        "    target_size=input_shape[:2],\n",
        "    shuffle=False,\n",
        "    seed=SEED,\n",
        "    class_mode='categorical',\n",
        "    batch_size=BATCH_SIZE,\n",
        ")\n",
        "\n",
        "## Image quantity\n",
        "train_samples = train_generator.samples\n",
        "validation_samples = validation_generator.samples\n",
        "test_samples = test_generator.samples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "cXXADDp_drHT",
        "outputId": "73bba3fe-81cf-42bb-be38-3cc153ad115d"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Visualize Examples\n",
        "plt.figure(figsize=(8,8))\n",
        "\n",
        "for i in range(9):\n",
        "    plt.subplot(330 + 1 + i)\n",
        "    batch = train_generator.next()[0]*255\n",
        "    image = batch[0].astype('uint8')\n",
        "    plt.imshow(image)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bq57gTj9e2sP"
      },
      "source": [
        "### Carregando o modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fEjvW6nye4MO",
        "outputId": "4c701cc7-8529-4ac2-9adc-cbbd8d4e038e"
      },
      "outputs": [],
      "source": [
        "from keras.applications import InceptionV3\n",
        "from keras.layers import Dense, GlobalAveragePooling2D\n",
        "from keras.models import Model\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "# Load the InceptionV3 model with pre-trained weights (excluding top layers)\n",
        "base_model = InceptionV3(weights='imagenet', include_top=False, input_shape=input_shape)\n",
        "\n",
        "# Add custom top layers for your specific task\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(512, activation='relu')(x)\n",
        "predictions = Dense(n_classes, activation='softmax')(x)\n",
        "\n",
        "# Create the final model\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RWDBjWAGfIYJ"
      },
      "source": [
        "### Compilando e treinando o modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Verifique se uma GPU está disponível\n",
        "if tf.test.gpu_device_name():\n",
        "    print('GPU encontrada:')\n",
        "    print(tf.test.gpu_device_name())\n",
        "else:\n",
        "    print('GPU não encontrada.')\n",
        "\n",
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "    try:\n",
        "        # Limitar a alocação de memória da GPU\n",
        "        for gpu in gpus:\n",
        "            tf.config.experimental.set_memory_growth(gpu, True)\n",
        "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
        "        print(len(gpus), \"GPU(s) física(s),\", len(logical_gpus), \"GPU(s) lógica(s)\")\n",
        "    except RuntimeError as e:\n",
        "        print(e)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ylGf9uMLfMPt",
        "outputId": "0b2b8c8e-8b84-4273-be21-fefd6303b9ba"
      },
      "outputs": [],
      "source": [
        "EPOCHS = 50\n",
        "filepath='./InceptionV3/libras/'\n",
        "callbacks_list = [\n",
        "    keras.callbacks.ModelCheckpoint(\n",
        "        filepath=f'{filepath}inception_v3_weights.h5',\n",
        "        monitor='val_accuracy',\n",
        "        mode='max',\n",
        "        save_best_only=True,\n",
        "        save_weights_only=True,\n",
        "        verbose=1\n",
        "    ),\n",
        "    keras.callbacks.ModelCheckpoint(\n",
        "        filepath=f'{filepath}inception_v3_model.h5',\n",
        "        monitor='val_loss',\n",
        "        mode='min',\n",
        "        save_best_only=True,\n",
        "        save_weights_only=False,\n",
        "        verbose=1\n",
        "    ),\n",
        "    keras.callbacks.EarlyStopping(\n",
        "        monitor='val_loss',\n",
        "        patience=30,\n",
        "        restore_best_weights=True,\n",
        "        verbose=1,\n",
        "    ),\n",
        "]\n",
        "\n",
        "# Compiling Model\n",
        "model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "#Training\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    epochs=EPOCHS,\n",
        "    steps_per_epoch=train_samples//BATCH_SIZE,\n",
        "    callbacks = callbacks_list,\n",
        "    validation_data=validation_generator,\n",
        "    verbose = 1,\n",
        "    validation_steps=validation_samples//BATCH_SIZE,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xuu28_u3ghuB"
      },
      "source": [
        "# Testes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Wb1R7TUgoah"
      },
      "outputs": [],
      "source": [
        "import itertools\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "def classification_report_csv(report):\n",
        "  report_data = []\n",
        "  lines = report.split('\\n')\n",
        "  for line in lines[2:-3]:\n",
        "      row = {}\n",
        "      row_data = [d for d in line.split(' ') if d!='']\n",
        "      if (len(row_data) == 5):\n",
        "        row['class'] = row_data[0]\n",
        "        row['precision'] = float(row_data[1])\n",
        "        row['recall'] = float(row_data[2])\n",
        "        row['f1_score'] = float(row_data[3])\n",
        "        row['support'] = float(row_data[4])\n",
        "        report_data.append(row)\n",
        "  dataframe = pd.DataFrame.from_dict(report_data)\n",
        "  dataframe.to_csv(f'{filepath}classification_report.csv', index = False)\n",
        "\n",
        "#Plot the confusion matrix. Set Normalize = True/False\n",
        "def plot_confusion_matrix(cm, classes, normalize=True, title='Confusion matrix', cmap=plt.cm.Blues):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    plt.figure(figsize=(10,10))\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        cm = np.around(cm, decimals=2)\n",
        "        cm[np.isnan(cm)] = 0.0\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, cm[i, j],\n",
        "                 horizontalalignment=\"center\",\n",
        "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')\n",
        "    plt.savefig(f'{filepath}confusion_matrix.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "vWo6SiJigjNa",
        "outputId": "ffd1a5b1-36dc-4200-8fb4-d52d2b73d75c"
      },
      "outputs": [],
      "source": [
        "# Training curves\n",
        "history_dict = history.history\n",
        "loss_values = history_dict['loss']\n",
        "val_loss_values = history_dict['val_loss']\n",
        "\n",
        "epochs_x = range(1, len(loss_values) + 1)\n",
        "\n",
        "plt.figure(figsize=(15,15))\n",
        "\n",
        "plt.subplot(2,1,1)\n",
        "plt.plot(epochs_x, loss_values, 'bo', label='Training loss')\n",
        "plt.plot(epochs_x, val_loss_values, 'b', label='Validation loss')\n",
        "plt.title('Training and validation Loss and Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(2,1,2)\n",
        "acc_values = history_dict['accuracy']\n",
        "val_acc_values = history_dict['val_accuracy']\n",
        "plt.plot(epochs_x, acc_values, 'bo', label='Training acc')\n",
        "plt.plot(epochs_x, val_acc_values, 'b', label='Validation acc')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Acc')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()\n",
        "plt.savefig(f'{filepath}training_curves.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e6vJzaDsgm9q",
        "outputId": "d01e4ec4-ffed-4eb2-d492-783ea137ce74"
      },
      "outputs": [],
      "source": [
        "# Validation\n",
        "score = model.evaluate(validation_generator)\n",
        "print('Validation loss:', score[0])\n",
        "print('Validation accuracy:', score[1])\n",
        "\n",
        "# test\n",
        "score = model.evaluate(test_generator)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "6PchOO29gqXy",
        "outputId": "1e366359-5f95-40e7-c3b9-2b849315c4c9"
      },
      "outputs": [],
      "source": [
        "# Some reports\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import numpy as np\n",
        "\n",
        "# On test dataset\n",
        "Y_pred = model.predict(test_generator)\n",
        "y_pred = np.argmax(Y_pred, axis=1)\n",
        "target_names = classes\n",
        "\n",
        "# Confution Matrix\n",
        "cm = confusion_matrix(test_generator.classes, y_pred)\n",
        "plot_confusion_matrix(cm, target_names, normalize=False, title='Confusion Matrix')\n",
        "\n",
        "# Classification Report\n",
        "print('Classification Report')\n",
        "report = classification_report(test_generator.classes, y_pred, target_names=target_names)\n",
        "classification_report_csv(report)\n",
        "print(report)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
